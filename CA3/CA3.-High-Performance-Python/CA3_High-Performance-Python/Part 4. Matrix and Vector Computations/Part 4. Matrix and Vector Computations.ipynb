{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CA4. Multiprocessing**\n",
    "**Sulu Chi Yahir Benjamin\\\n",
    "Data Engineering\\\n",
    "Universidad Politécnica de Yucatán\\\n",
    "Ucú, Yucatán, México\\\n",
    "2109145@upy.edu.mx**\n",
    "\n",
    "\n",
    "# Part 4. Matrix and Vector Computations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Read about Broadcasting with Arrays on the chapter Computation on Arrays:\\\n",
    "Broadcasting from Python Data Science Handbook (J. VandePlas, 2016):\\\n",
    "**Link:** https://jakevdp.github.io/PythonDataScienceHandbook/02.05-computationon-arrays-broadcasting.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The description outlines NumPy's pivotal components for streamlined computation, emphasizing its reliance on vectorized operations and the groundbreaking concept of broadcasting. It delves into the mechanics of universal functions (ufuncs), which serve as the engine behind rapid array computations. By leveraging unary and binary operations like arithmetic, trigonometry, and logarithms, ufuncs circumvent Python's inherent loop sluggishness, catapulting efficiency.\n",
    "\n",
    "Furthermore, the discourse accentuates the specialized functionalities of ufuncs, including output specification, aggregates, and outer products, which bolster NumPy's computational prowess. Broadcasting emerges as a standout attribute, enabling seamless vectorized operations across arrays of disparate shapes sans explicit data replication. This streamlined approach not only simplifies code but also augments performance, adhering to NumPy's ethos of computational efficiency.\n",
    "\n",
    "The narrative delineates the rules guiding broadcasting in NumPy, such as dimension extension and avoidance of data duplication, crucial for optimizing computational and memory resources in high-performance computing (HPC) environments. These rules underpin the versatility of NumPy's binary universal functions, catering to diverse mathematical operations with finesse.\n",
    "\n",
    "Moreover, illustrative examples underscore broadcasting's utility in data processing, scientific analysis, and machine learning tasks, showcasing its role in operations like array centering and grid-based function computation. In the realm of HPC and matrix/vector computations, broadcasting emerges as an indispensable tool for executing vectorized operations efficiently. Its role in simplifying coding, enhancing computational speed, and fostering flexibility in algorithmic design underscores its significance in numerical computing landscapes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. Read Rewriting the particle simulator in Numpy on Chapter 2: Fast Array Operations\n",
    "with Numpy and Pandas (pp. 68) from the book G. Lenaro (2017). Python high\n",
    "Performance. Second Edition. UK: Packt Publishing Ltd. Implement the\n",
    "improvements on the particle simulator using NumPy. Show that both\n",
    "implementations scale linearly with particle size, but the runtime in the pure Python\n",
    "version grows much faster than the NumPy version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\angel\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (1.26.4)\n",
      "Collecting numexpr\n",
      "  Downloading numexpr-2.10.0-cp310-cp310-win_amd64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\angel\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from numexpr) (1.26.4)\n",
      "Downloading numexpr-2.10.0-cp310-cp310-win_amd64.whl (97 kB)\n",
      "   ---------------------------------------- 97.0/97.0 kB 923.4 kB/s eta 0:00:00\n",
      "Installing collected packages: numexpr\n",
      "Successfully installed numexpr-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, x, y, ang_vel):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.ang_vel = ang_vel\n",
    "\n",
    "class ParticleSimulator:\n",
    "    def __init__(self, particles):\n",
    "        self.particles = particles\n",
    "\n",
    "    def evolve_python(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    "\n",
    "        for _ in range(nsteps):\n",
    "            for p in self.particles:\n",
    "                norm = (p.x**2 + p.y**2)**0.5\n",
    "                v_x = (-p.y) / norm\n",
    "                v_y = p.x / norm\n",
    "                d_x = timestep * p.ang_vel * v_x\n",
    "                d_y = timestep * p.ang_vel * v_y\n",
    "                p.x += d_x\n",
    "                p.y += d_y\n",
    "\n",
    "    def evolve_numpy(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    "        r_i = np.array([[p.x, p.y] for p in self.particles])\n",
    "        ang_vel_i = np.array([p.ang_vel for p in self.particles])\n",
    "\n",
    "        for _ in range(nsteps):\n",
    "            norm_i = np.sqrt((r_i ** 2).sum(axis=1))\n",
    "            v_i = r_i[:, [1, 0]] * np.array([-1, 1]) / norm_i[:, np.newaxis]\n",
    "            d_i = timestep * ang_vel_i[:, np.newaxis] * v_i\n",
    "            r_i += d_i\n",
    "\n",
    "        for i, p in enumerate(self.particles):\n",
    "            p.x, p.y = r_i[i]\n",
    "\n",
    "def benchmark(npart=100, method='python'):\n",
    "    particles = [Particle(uniform(-1.0, 1.0), uniform(-1.0, 1.0), uniform(-1.0, 1.0)) for _ in range(npart)]\n",
    "    simulator = ParticleSimulator(particles)\n",
    "\n",
    "    if method == 'python':\n",
    "        simulator.evolve_python(0.1)\n",
    "    elif method == 'numpy':\n",
    "        simulator.evolve_numpy(0.1)\n",
    "\n",
    "# Example of benchmarking\n",
    "if __name__ == \"__main__\":\n",
    "    from timeit import timeit\n",
    "\n",
    "    print(\"Benchmarking with 100 particles:\")\n",
    "    print(\"Python version:\", timeit(\"benchmark(100, 'python')\", globals=globals(), number=1), \"seconds\")\n",
    "    print(\"NumPy version:\", timeit(\"benchmark(100, 'numpy')\", globals=globals(), number=1), \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15. Explain how to optain the optimal performance with numexpr. Read the section\n",
    "Reaching optimal performance with numexpr, pp. 72 from the previous reference.\n",
    "Implement it and measure the execution time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy revolutionizes computational efficiency by harnessing array broadcasting and memory optimization, particularly vital for handling vast datasets. Comparative benchmarks vividly demonstrate the exponential performance gains as one transitions from conventional Python loops to NumPy's lightning-fast vectorized operations, especially evident with larger datasets.\n",
    "\n",
    "Expanding upon NumPy's groundwork, Numexpr elevates these advancements by fine-tuning array expressions, curbing memory usage, and tapping into multiple CPU cores for parallel processing. By sidestepping intermediate array storage and maximizing CPU cache utilization, Numexpr achieves remarkable speed enhancements in operations involving extensive arrays.\n",
    "\n",
    "These strides shine in practical scenarios like norm calculations and particle displacement analyses, where Numexpr's knack for compiling and streamlining complex expressions in real-time leads to substantial performance leaps beyond traditional NumPy methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import uniform\n",
    "import numexpr as ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, x, y, ang_vel):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.ang_vel = ang_vel\n",
    "class ParticleSimulator:\n",
    "    def __init__(self, particles):\n",
    "        self.particles = particles\n",
    "    def evolve_python(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    "        for i in range(nsteps):\n",
    "            for p in self.particles:\n",
    "                norm = (p.x**2 + p.y**2)**0.5\n",
    "                v_x = (-p.y) / norm\n",
    "                v_y = p.x / norm\n",
    "                d_x = timestep * p.ang_vel * v_x\n",
    "                d_y = timestep * p.ang_vel * v_y\n",
    "                p.x += d_x\n",
    "                p.y += d_y\n",
    "    def evolve_numpy(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    "        r_i = np.array([[p.x, p.y] for p in self.particles])\n",
    "        ang_vel_i = np.array([p.ang_vel for p in self.particles])\n",
    "        for i in range(nsteps):\n",
    "            norm_i = np.sqrt((r_i ** 2).sum(axis=1))\n",
    "            v_i = r_i[:, [1, 0]] * np.array([-1, 1]) / norm_i[:, np.newaxis]\n",
    "            d_i = timestep * ang_vel_i[:, np.newaxis] * v_i\n",
    "            r_i += d_i\n",
    "        for i, p in enumerate(self.particles):\n",
    "            p.x, p.y = r_i[i]\n",
    " \n",
    "    def evolve_numexpr(self, dt):\n",
    "        timestep = 0.00001\n",
    "        nsteps = int(dt / timestep)\n",
    "        r_i = np.array([[p.x, p.y] for p in self.particles])\n",
    "        ang_vel_i = np.array([p.ang_vel for p in self.particles])\n",
    " \n",
    "        for i in range(nsteps):\n",
    "            norm_i = ne.evaluate(\"sqrt((r_i ** 2).sum(axis=1))\")\n",
    "            v_i = r_i[:, [1, 0]]\n",
    "            v_i[:, 0] = ne.evaluate(\"-v_i[:, 0]\")\n",
    "            v_i = ne.evaluate(\"v_i / norm_i[:, None]\")\n",
    "            d_i = ne.evaluate(\"timestep * ang_vel_i[:, None] * v_i\")\n",
    "            r_i = ne.evaluate(\"r_i + d_i\")\n",
    " \n",
    "        for i, p in enumerate(self.particles):\n",
    "            p.x, p.y = r_i[i]\n",
    " \n",
    "def benchmark(npart=100000, method='python'):\n",
    "    particles = [Particle(uniform(-1.0, 1.0), uniform(-1.0, 1.0), uniform(-1.0, 1.0)) for _ in range(npart)]\n",
    "    simulator = ParticleSimulator(particles)\n",
    "    if method == 'python':\n",
    "        simulator.evolve_python(0.1)\n",
    "    elif method == 'numpy':\n",
    "        simulator.evolve_numpy(0.1)\n",
    "    elif method == 'numexpr':\n",
    "        simulator.evolve_numpy(0.1)\n",
    " \n",
    "# Example of benchmarking\n",
    "if __name__ == \"__main__\":\n",
    "    from timeit import timeit\n",
    "    print(\"Benchmarking with 100000 particles:\")\n",
    "    print(\"Python version:\", timeit(\"benchmark(100000, 'python')\", globals=globals(), number=1), \"seconds\")\n",
    "    print(\"NumPy version:\", timeit(\"benchmark(100000, 'numpy')\", globals=globals(), number=1), \"seconds\")\n",
    "    print(\"NumExpr version:\", timeit(\"benchmark(100000, 'numexpr')\", globals=globals(), number=1), \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
